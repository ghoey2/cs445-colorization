{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7dfe4-fb16-4c41-b472-67a9b6f3df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import colorizationnet \n",
    "import colorizationdataset\n",
    "from colorizationnet import ColorizationCNN\n",
    "from colorizationdataset import ColorizationDataset, read_in_data\n",
    "from train import train\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1656123-0ff3-47d0-a151-6feb40fc5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = .01\n",
    "num_epochs = 5\n",
    "\n",
    "num_channels_in = 1\n",
    "num_channels_out = 2\n",
    "im_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26c0ef-2c92-4852-bffa-1581e5d37fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in data as lab images of size (256, 256) [image_num, y, x, channel]\n",
    "\n",
    "train_color_ims, test_color_ims = read_in_data(\"data/colorimages\", im_size)\n",
    "train_dataset = ColorizationDataset(train_color_ims[:,:,:,0], train_color_ims)\n",
    "test_dataset = ColorizationDataset(test_color_ims[:,:,:,0], test_color_ims)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547c354-9e5b-4d04-bc93-812818714e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "model = ColorizationCNN(learning_rate, criterion, num_channels_in, num_channels_out, im_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18beacfa-55f8-4cd0-a059-0b1fd133dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model, train_loader, criterion, optimizer, num_epochs, isDebug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16069846-a26b-4e8d-8a0f-dfa9f3b6354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "model.eval() \n",
    "output_imgs = []\n",
    "vgg = models.vgg19(pretrained=True).eval()\n",
    "current_correct = 0\n",
    "current_total = 0\n",
    "correct_fake = 0\n",
    "total = 0\n",
    "best_accuracy = 0\n",
    "best_idx = 0\n",
    "with torch.no_grad():\n",
    "    for i,sample in enumerate(test_dataset):\n",
    "        grey = sample['input']\n",
    "        color = sample['output']\n",
    "        colorized_images = model.forward(grey)\n",
    "        colorized_images = np.stack((grey, (colorized_images[:,:,0]).detach().numpy() * 255, (colorized_images[:,:,1]).detach().numpy() * 255), axis=-1)\n",
    "        \n",
    "\n",
    "        colorized_images = torch.tensor(colorized_images).float().unsqueeze(0)\n",
    "        colorized_images = colorized_images.permute(0, 3, 2, 1)\n",
    "        color = torch.tensor(color).float().unsqueeze(0)\n",
    "        color = color.permute(0, 3, 2, 1)\n",
    "        #print(color.shape)\n",
    "        outputs_fake = vgg(colorized_images) #run our fake colorized images thru VGG and see the scores\n",
    "        outputs_real = vgg(color) #get the real labels using the output\n",
    "\n",
    "        _, predicted_fake = torch.max(outputs_fake.data, 1) #take the scores and get the prediction (which label has highest score)\n",
    "        _, predicted_real = torch.max(outputs_real.data, 1)\n",
    "        current_correct += (predicted_fake == predicted_real).sum().item() #how many predictions are correct\n",
    "        correct_fake += current_correct\n",
    "        current_total = len(sample['input']) \n",
    "        total += current_total\n",
    "\n",
    "        colorized_images = colorized_images.permute(0, 2, 3, 1)\n",
    "        colorized_images = colorized_images.squeeze(0)\n",
    "        output_imgs.append(colorized_images)\n",
    "\n",
    "        if (current_correct / current_total) > best_accuracy:\n",
    "          best_accuracy = current_correct / current_total\n",
    "          best_idx = i\n",
    "\n",
    "accuracy = 100 * correct_fake / total\n",
    "\n",
    "print(f'Accuracy on fake colorized images from model: {accuracy}%') #total accuracy of model\n",
    "\n",
    "lab_image = output_imgs[best_idx]\n",
    "rgb_image = lab2rgb(lab_image)\n",
    "output_directory = 'data/outputimages'\n",
    "\n",
    "scaled_rgb_image = rgb_image * 255.0\n",
    "\n",
    "# Clip the values to ensure they are within the valid range [0, 255]\n",
    "scaled_rgb_image = np.clip(scaled_rgb_image, 0, 255)\n",
    "output_file_path = os.path.join(output_directory, 'output_image.png')\n",
    "plt.imshow(rgb_image)\n",
    "plt.axis('off') \n",
    "plt.savefig(output_file_path)\n",
    "\n",
    "output_file_path = os.path.join(output_directory, 'scaled_output_image.png')\n",
    "plt.imshow(np.array(scaled_rgb_image))\n",
    "plt.axis('off') \n",
    "plt.savefig(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
